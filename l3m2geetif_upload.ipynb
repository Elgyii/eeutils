{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA L3M2GeoTiff & GEE Upload\n",
    "\n",
    "\n",
    "## Purpose\n",
    "Convert Nasa gridded files to geotiff and send to the GEE.\n",
    "\n",
    "## Methodology\n",
    "1. Create projection using pyproj to get projected area extent.\n",
    "2. Create a 2D resampling grid using pyresample AreaDefinition.from_extent. Pyresample needs the following\n",
    "\n",
    "**Shape** <br>\n",
    ">Lat: 4320 / number of equal boxes.  <br>\n",
    ">Lon: 8640 / number of equal boxes.\n",
    "\n",
    "\n",
    "## Results\n",
    "Uploaded geotiffs in the GEE\n",
    "\n",
    "\n",
    "## Suggested next steps\n",
    "State suggested next steps, based on results obtained in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "## Library import\n",
    "We import all the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from calendar import timegm\n",
    "import numpy as np\n",
    "import pyproj\n",
    "from pyresample import geometry\n",
    "from glob import glob\n",
    "\n",
    "from datetime import datetime\n",
    "from osgeo import gdal, gdal_array, osr\n",
    "from netCDF4 import (Dataset, date2num)\n",
    "from datafetch.nasa_l3 import getfile\n",
    "from eeutils.togeotiff import toGeotiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ee\n",
    "# ee.Authenticate()\n",
    "# ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up the Working Environment\n",
    ">Define the input directory containing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = 'F:\\\\Global'                                          # Input directory\n",
    "OUTPUT_DIR = 'F:\\\\Global'                                         # Output directory. Update for each sensor\n",
    "START = datetime(2003, 1, 31)                                     # Upload start date\n",
    "END = datetime(2003, 2, 2)                                        # Upload end date\n",
    "COMP = 'day'                                                      # File composite period\n",
    "VAR = 'chlor_a'                                                   # Variable\n",
    "BUCKET = 'gs://abcd'\n",
    "DTYPE = 'l3m'                                                     # Data type, mapped or binned \n",
    "PROJ_ID = 'eqc'                                                   # map_projection = 'Equidistant Cylindrical'\n",
    "SRC_SRS = 'EPSG:4087'                                             # Equidistant Cylindrical SRS of input file\n",
    "TRG_SRS = 'EPSG:4326'                                             # SRS of output file | Google\n",
    "FMT = '%Y-%m-%dT%H:%M:%S.%fZ'                                     # Ocean colour date format\n",
    "SENSORS = {'modis': 'MODIS-Aqua', 'viirs': 'VIIRS-SNPP', \n",
    "           'seawifs': 'SeaWiFS', 'meris': 'MERIS'}                # Sensors\n",
    "FILELIST = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import/Download/Read Data\n",
    "> ## Global gridded L3m file\n",
    "> ### Geotiff, gdal translate, upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, val in SENSORS.items():\n",
    "    if key != 'modis':\n",
    "        continue\n",
    "        \n",
    "    init = 'A' if key == 'modis' else sen[0]\n",
    "    nc = f'{INPUT_DIR}\\\\{val}\\\\{COMP.capitalize()}\\\\nc'\n",
    "    if not os.path.isdir(nc):\n",
    "        os.makedirs(nc)\n",
    "    tif = f'{INPUT_DIR}\\\\{val}\\\\{COMP.capitalize()}\\\\tif'\n",
    "    if not os.path.isdir(tif):\n",
    "        os.makedirs(tif)\n",
    "    \n",
    "    files = glob(f'{nc}\\\\*.nc')\n",
    "    n = len(files)\n",
    "    if n < (END.toordinal() - START.toordinal()):\n",
    "        FILELIST[key] = getfile(var=VAR, sen=key, dtype=DTYPE, comp=COMP, \n",
    "                                sdate=START, edate=END, output_dir=nc)\n",
    "    else:\n",
    "        files = []\n",
    "        for d in range(START.toordinal(), END.toordinal() + 1):\n",
    "            f = glob(f'{nc}/{init}{datetime.fromordinal(d).strftime(\"%Y%j\")}*.nc')\n",
    "            if len(f) == 0:\n",
    "                f = getfile(var=VAR, sen=key, dtype=DTYPE, comp=COMP, output_dir=nc, \n",
    "                        sdate=datetime.fromordinal(d), edate=datetime.fromordinal(d))\n",
    "                files.append(f)\n",
    "            else:\n",
    "                files.extend(f)\n",
    "        FILELIST[key] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmv_file(file: str):\n",
    "    if os.name == 'nt':\n",
    "        os.system(f'del /f {file} >nul')\n",
    "    if os.name == 'posix':\n",
    "        os.system(f'rm -f {file} 2> /dev/null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Upload manifest builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_manifest(asset_dict:dict, disp:bool=False):\n",
    "\n",
    "    # The enclosing object for the asset.\n",
    "    asset = {\n",
    "        'name': asset_dict['asset_id'],\n",
    "        'tilesets': [\n",
    "            {'sources': [\n",
    "                {\"uris\": [asset_dict['source']]}]}],\n",
    "        'bands': [\n",
    "            {'id': asset_dict['var'],\n",
    "             'missing_data': {'values': [int(asset_dict['missing_data'])]}}],\n",
    "        \"start_time\": {\"seconds\": asset_dict['start_time']},\n",
    "        \"end_time\": {\"seconds\": asset_dict['end_time']},\n",
    "        \"properties\": asset_dict['attributes']\n",
    "    }\n",
    "    if disp:\n",
    "        print(json.dumps(asset, indent=2))\n",
    "    \n",
    "    jason_manifest = 'temp_manifest.json'\n",
    "    with open(jason_manifest, 'w') as f:\n",
    "        json.dump(asset, f, indent=2)\n",
    "    return jason_manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Gdal translate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gdal_trans(infile:str, outfile:str, fill_value):\n",
    "    cmd = f'gdal_translate -a_nodata {fill_value} -a_srs {TRG_SRS} {infile} {outfile}'\n",
    "    exit = os.system(cmd)\n",
    "    rmv_file(file=infile)\n",
    "    return exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### gsutil file uploader function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gsupload(trg:str, bucket:str):\n",
    "    basename = os.path.basename(trg)\n",
    "    gc_file = f'{bucket}/{basename}'\n",
    "    \n",
    "    cloud_file = !gsutil ls {gc_file}\n",
    "    exit = None\n",
    "    if 'CommandException' in cloud_file[0]:\n",
    "        print(f'\\tGSUTIL\\n\\t{\"=\"*10}\\n\\tgsutil cp {trg} {gc_file}\\n')\n",
    "        gs_cmd = f'gsutil cp {trg} {gc_file}'\n",
    "        # To see the upload progress, use sys\n",
    "        exit = os.system(gs_cmd)\n",
    "    return gc_file, exit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Create asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_asset(asset_id:str):\n",
    "    \n",
    "    tmp_file = 'create_asset_tmp.txt'\n",
    "    !earthengine --no-use_cloud_api ls -m 1 {asset_id} > {tmp_file}\n",
    "    with open(tmp_file, 'r') as txt:\n",
    "        res = ''.join([line.strip('\\n') for line in txt.readlines()])\n",
    "    \n",
    "    if 'not found.' in res:\n",
    "        print(f'CreateAsset\\nearthengine --no-use_cloud_api create collection -p {asset_id}')\n",
    "        !earthengine --no-use_cloud_api create collection -p {asset_id}\n",
    "    rmv_file(file=tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### List of asset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asset_list(asset_id: str):\n",
    "    tmp_file = 'ee_asset_filelist.txt'\n",
    "    !earthengine --no-use_cloud_api ls {asset_id} > {tmp_file}\n",
    "    with open(tmp_file, 'r') as txt:\n",
    "        res = [f\"{os.path.basename(line.strip('\\n'))}.tif\" \n",
    "               for line in txt.readlines()]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file: str, tifile: str, append):\n",
    "    \n",
    "    data, extend, fill_value = None, None, None\n",
    "    \n",
    "    with Dataset(src, 'r') as nc:\n",
    "        if not os.path.isfile(tifile):\n",
    "            data = nc[VAR][:]\n",
    "\n",
    "            x0 = nc.geospatial_lon_min\n",
    "            y0 = nc.geospatial_lat_min\n",
    "            x1 = nc.geospatial_lon_max\n",
    "            y1 = nc.geospatial_lat_max\n",
    "            extent = [x0, y0, x1, y1]\n",
    "\n",
    "        # var attributes\n",
    "        fill_value = nc[VAR].getncattr('_FillValue')\n",
    "        var_attrs = {key:nc[VAR].getncattr(key)\n",
    "                     for key in nc[VAR].ncattrs() \n",
    "                     if not (key.startswith('_') or \n",
    "                             ('valid_m' in key) or \n",
    "                             ('display_m' in key))}\n",
    "        append((datetime.strptime(nc.getncattr('time_coverage_start'), FMT), \n",
    "                datetime.strptime(nc.getncattr('time_coverage_end'), FMT), var_attrs))\n",
    "                \n",
    "        # append((timegm(time.strptime(nc.getncattr('time_coverage_start'), FMT)), \n",
    "        #         timegm(time.strptime(nc.getncattr('time_coverage_end'), FMT)), var_attrs))\n",
    "    return data, extend, fill_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gee_upload(ee_dict: dict):\n",
    "    \n",
    "    fmt = '%Y-%m-%dT%H:%M:%S' \n",
    "    bsn = os.path.basename(ee_dict[\"source\"]).strip('.tif')\n",
    "    ee_cmd = f'earthengine --no-use_cloud_api upload image {ee_dict[\"source\"]} ' \\\n",
    "             f'--time_start \"{ee_dict[\"start_time\"].strftime(fmt)}\" ' \\\n",
    "             f'--time_end \"{ee_dict[\"end_time\"].strftime(fmt)}\" ' \\\n",
    "             f'--bands {ee_dict[\"var\"]} ' \\\n",
    "             f'--nodata_value {ee_dict[\"missing_data\"]} ' \\\n",
    "    \n",
    "    ee_cmd = ''.join([ee_cmd] + \n",
    "                     [f'--property {key}=\"{val}\" ' \n",
    "                      for key, val in ee_dict[\"attributes\"].items()] + \n",
    "                     [f'--asset_id=\"{ee_dict[\"asset_id\"]}/{bsn}\" >> gee_uploads.txt'])\n",
    "    \n",
    "    # !earthengine --no-use_cloud_api upload image --manifest {manifest}\n",
    "    print(f'EE\\n\\t{\"=\"*10}\\n\\t{ee_cmd}\\n')\n",
    "    exit = os.system(ee_cmd)\n",
    "    return exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tasks = f'tasks_{datetime.today().strftime(\"%Y%m%d\")}.txt'\n",
    "# os.system(f'earthengine --no-use_cloud_api task list > {tasks}')\n",
    "# with open(tasks, 'r') as txt:\n",
    "#     for line in txt.readlines():\n",
    "#         if 'COMPLETED' in line:\n",
    "#             continue\n",
    "#         if 'FAILED' in line:\n",
    "#             task_id = line.split(' ')[0]\n",
    "#             os.system(f'earthengine --no-use_cloud_api task cancel {task_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, val in SENSORS.items():\n",
    "    print(f'Sen: {val}')\n",
    "    if key not in FILELIST.keys():\n",
    "        continue\n",
    "    # OCEANCOLOUR/MODIS-Aqua/L3M\n",
    "    sen = f'{val}/L3M'\n",
    "    asset_id = f'users/username/OCEANCOLOUR/{sen}'\n",
    "    create_asset(asset_id=asset_id)\n",
    "    \n",
    "    asst_list = asset_list(asset_id=asset_id)\n",
    "\n",
    "    nc = f'{INPUT_DIR}\\\\{val}\\\\{COMP.capitalize()}\\\\nc'\n",
    "    tif = f'{INPUT_DIR}\\\\{val}\\\\{COMP.capitalize()}\\\\tif'\n",
    "    nctimes = []\n",
    "    gtfiles = []\n",
    "    append = nctimes.append\n",
    "    fill_value = None\n",
    "    \n",
    "    for i, src in enumerate(FILELIST[key]):\n",
    "        print(f'\\t{i:3}# | File: {src}')\n",
    "        \n",
    "        # Generate the Gtiff file\n",
    "        trg = f\"{tif}\\\\{os.path.basename(src).replace('.nc', '.tif')}\"\n",
    "        trg_new = trg.split('.')[0] + '.tif'\n",
    "        \n",
    "        data, extent, fill_value = get_data(file=src, tifile=trg_new, append=append)\n",
    "        if data is not None:\n",
    "            gt, srs = toGeotiff(data=data, proj_id=PROJ_ID, extent=extent, \n",
    "                                output_file=trg, fill_value=fill_value)\n",
    "\n",
    "            # Gdal translate\n",
    "            exit = gdal_trans(infile=trg, outfile=trg_new, fill_value=fill_value)\n",
    "        gtfiles.append(trg_new)\n",
    "        \n",
    "    # Upload to GC\n",
    "    for i, trg in enumerate(gtfiles):\n",
    "        print(f'{i:3}# | File: {trg}')\n",
    "        uirs, exit = gsupload(trg=trg)\n",
    "        \n",
    "        if os.path.basename(uirs) in asset_list:\n",
    "            !gsutil rm {uirs}\n",
    "            continue\n",
    "            \n",
    "        # Jason dict \n",
    "        asset_dict = {'asset_id':asset_id, 'missing_data': fill_value, 'var': VAR, \n",
    "                      'start_time': nctimes[i][0], 'end_time': nctimes[i][1], \n",
    "                      'attributes': nctimes[i][2], 'source': uirs}\n",
    "        # Build upload manifest\n",
    "        #manifest = build_manifest(asset_dict=asset_dict)\n",
    "\n",
    "        # Do the upload. \n",
    "        gee_upload(ee_dict=asset_dict, bucket=BUCKET)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud_file = !gsutil ls {gc_file}\n",
    "# 'CommandException' in cloud_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asst_id = 'users/\n",
    "# tmp_file = 'eetmp.txt'\n",
    "# !earthengine --no-use_cloud_api ls {asst_id} > {tmp_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ee\n",
    "# ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# asst_id = 'users/\n",
    "# image = ee.Image(asst_id)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.imshow(image.load)\n",
    "# image.getInfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
